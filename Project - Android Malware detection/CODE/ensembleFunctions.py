import svmFunctions
import numpy as np
import copy
import treeFunctions
from collections import Counter
import treeFunctions
import math
import random
import csv
import treeFunctions
import projectFunctions
from sklearn import tree

def features_n_labels_matrix(featureMat, labelMat):
    finalmatrix = []
    for i in range(len(featureMat)):
        g = np.append(featureMat[i],labelMat[i])
        finalmatrix.append(g.tolist())
        npArray = np.array(finalmatrix)
    return npArray

def file_to_matrices(filepath):
    file = open(filepath, 'rb')
    data = csv.reader(file, delimiter=' ')
    matrix = [row for row in data]
    labels = []
    Totalmatrix = []
    maxFtrCol = 0
    for i in range(len(matrix)):
        lineData = csv.reader(matrix[i], delimiter=':')
        rowmatrix = [row for row in lineData]
        T2 = [map(int, x) for x in rowmatrix]
        labelElement = T2[0][0]
        labels.append(labelElement)
        for j in range(1, len(T2)):
            tempo = T2[j][0]
            if ((tempo) > maxFtrCol):
                maxFtrCol = tempo
        Totalmatrix.append(T2)
    finalMatrix = np.zeros((len(matrix), maxFtrCol))
    for i in range(len(Totalmatrix)):
        for j in range(1, (len(Totalmatrix[i]))):
            finalMatrix[i][Totalmatrix[i][j][0] - 1] = Totalmatrix[i][j][1]

    labels = np.asarray(labels)
    return finalMatrix, labels

def saveData(train_wholeMAT, train_labels, m_train_labels, test_wholeMAT, m_test_labels, eval_wholeMAT, m_eval_labels):
    np.save('transformedDATA\TREESwithSTDEVbucketting\_train_wholeMAT',train_wholeMAT)
    np.save('transformedDATA\TREESwithSTDEVbucketting\_train_labels', train_labels)
    np.save('transformedDATA\TREESwithSTDEVbucketting\_m_train_labels', m_train_labels)
    np.save('transformedDATA\TREESwithSTDEVbucketting\_test_wholeMAT', test_wholeMAT)
    #np.save('transformedDATA\TREESwithSTDEVbucketting\_test_labels', test_labels)
    np.save('transformedDATA\TREESwithSTDEVbucketting\_m_test_labels', m_test_labels)
    np.save('transformedDATA\TREESwithSTDEVbucketting\_eval_wholeMAT', eval_wholeMAT)
    #np.save('transformedDATA\TREESwithSTDEVbucketting\_eval_labels', eval_labels)
    np.save('transformedDATA\TREESwithSTDEVbucketting\_m_eval_labels', m_eval_labels)

def loadData():
    train_wholeMAT = np.load('transformedDATA\TREESwithSTDEVbucketting\_train_wholeMAT.npy')
    train_labels = np.load('transformedDATA\TREESwithSTDEVbucketting\_train_labels.npy')
    m_train_labels = np.load('transformedDATA\TREESwithSTDEVbucketting\_m_train_labels.npy')
    test_wholeMAT = np.load('transformedDATA\TREESwithSTDEVbucketting\_test_wholeMAT.npy')
    m_test_labels = np.load('transformedDATA\TREESwithSTDEVbucketting\_m_test_labels.npy')
    eval_wholeMAT = np.load('transformedDATA\TREESwithSTDEVbucketting\_eval_wholeMAT.npy')
    m_eval_labels = np.load('transformedDATA\TREESwithSTDEVbucketting\_m_eval_labels.npy')

    return train_wholeMAT, train_labels, m_train_labels, test_wholeMAT, m_test_labels, eval_wholeMAT, m_eval_labels

def readDATA_from_two_files(matrixPATH, labelsPATH):
    matriX = np.array(svmFunctions.read_file(matrixPATH))
    labelS = np.array(svmFunctions.read_file(labelsPATH))
    labelS = [item for sublist in labelS for item in sublist]
    finalmatrix = features_n_labels_matrix(matriX, labelS)
    return finalmatrix, labelSs

def readDATA_OneFile_and_transform(trainMATpath, testMATpath, evalMATpath):
    #read the features and lebel matrices
    trainMATRIX, trainLABELS = file_to_matrices(trainMATpath)
    testMATRIX, testLABELS = file_to_matrices(testMATpath)
    evalMATRIX, evalLABELS = file_to_matrices(evalMATpath)
    #transform the feature matrices
    stdConstant = 0.5
    trainMATRIX_transformed, testMATRIX_transformed, evalMATRIX_transformed = featureTransformation(trainMATRIX, testMATRIX, evalMATRIX, stdConstant)
    #Combine the feature and label matrices
    finalTRAINmatrix = features_n_labels_matrix(trainMATRIX_transformed, trainLABELS)
    finalTESTmatrix = features_n_labels_matrix(testMATRIX_transformed, testLABELS)
    finalEVALmatrix = features_n_labels_matrix(evalMATRIX_transformed, evalLABELS)
    #
    m_trainLABELS = zeroToMinusOne(trainLABELS)
    m_testLABELS = zeroToMinusOne(testLABELS)
    m_evalLABELS = zeroToMinusOne(evalLABELS)
    saveData(finalTRAINmatrix, trainLABELS, m_trainLABELS, finalTESTmatrix, m_testLABELS, finalEVALmatrix, m_evalLABELS)
    #return finalTRAINmatrix, trainLABELS, m_trainLABELS, finalTESTmatrix, m_testLABELS, finalEVALmatrix, m_evalLABELS

def zeroToMinusOne(trainLabels):
    finallabels = []
    for i in range(len(trainLabels)):
        finallabels.append(2*trainLabels[i]-1)
    return np.asarray(finallabels)

def featureTransformation(trainMatrix, testMatrix, evalMatrix, stdConstant):
    #'below code is for outliers'
    numTrainRows = len(trainMatrix)
    numTrainFeatures = len(trainMatrix[0])
    numTestRows = len(testMatrix)
    numEvalRows = len(evalMatrix)
    for f in range(numTrainFeatures):
        stDev = np.std(trainMatrix[:, f])
        meaN = np.mean(trainMatrix[:, f])
        upLimit = meaN + stDev*stdConstant
        lowLimit = meaN - stDev*stdConstant
        numBuckets = math.ceil(math.sqrt(stDev))
        if numBuckets == 0:
            bucketSize = 1
        else:
            bucketSize = math.ceil((upLimit -lowLimit)/ numBuckets)
        for r in range(numTrainRows):
            if trainMatrix[r][f] > upLimit:
                trainMatrix[r][f] = upLimit
            if trainMatrix[r][f] < lowLimit:
                trainMatrix[r][f] = lowLimit
            trainMatrix[r][f] = math.ceil(trainMatrix[r][f] / bucketSize)
            if r < numTestRows:
                if testMatrix[r][f] > upLimit:
                    testMatrix[r][f] = upLimit
                if testMatrix[r][f] < lowLimit:
                    testMatrix[r][f] = lowLimit
                testMatrix[r][f] = math.ceil(testMatrix[r][f] / bucketSize)
            if r < numEvalRows:
                if evalMatrix[r][f] > upLimit:
                    evalMatrix[r][f] = upLimit
                if evalMatrix[r][f] < lowLimit:
                    evalMatrix[r][f] = lowLimit
                evalMatrix[r][f] = math.ceil(evalMatrix[r][f] / bucketSize)

    return trainMatrix, testMatrix, evalMatrix

def randomSampleTreeEnsembles(train_MATRIX, train_LABELS, test_MATRIX, eval_MATRIX, N, mPercent, featureSplit):
    ensembleDataset_train_TRANS = []
    ensembleDataset_test_TRANS = []
    ensembleDataset_eval_TRANS = []
    numSamples = int(math.ceil(len(train_MATRIX) * mPercent))
    for numTrees in range(N):
        Sdata = np.array([random.choice(train_MATRIX) for _ in range(numSamples)])
        #Sdata = train_MATRIX
        predicted_train_list = []
        predicted_test_list = []
        predicted_eval_list = []
        #
        num_TrainingFEATURES = len(Sdata[0])-1
        depth_of_tree = 0; limiting_depth = 10000;
        to_be_visited = range(num_TrainingFEATURES)
        major_trainLABEL = (Counter(train_LABELS)).most_common(1)[0][0]
        tree = treeFunctions.k_feautres_ID3_tree(Sdata, num_TrainingFEATURES, depth_of_tree, to_be_visited, limiting_depth,featureSplit)
        #tree = treeFunctions.simple_ID3_tree(Sdata, num_TrainingFEATURES, depth_of_tree, to_be_visited, limiting_depth)
        list_of_labels = list(Counter(train_LABELS))
        predicted_train_list = treeFunctions.predictFUNCTION(tree, train_MATRIX, list_of_labels, major_trainLABEL)
        predicted_test_list = treeFunctions.predictFUNCTION(tree, test_MATRIX, list_of_labels, major_trainLABEL)
        predicted_eval_list = treeFunctions.predictFUNCTION(tree, eval_MATRIX, list_of_labels, major_trainLABEL)
        ensembleDataset_train_TRANS.append(predicted_train_list)
        ensembleDataset_test_TRANS.append(predicted_test_list)
        ensembleDataset_eval_TRANS.append(predicted_eval_list)

    ensembleDataset_train = np.transpose(np.array(ensembleDataset_train_TRANS))
    ensembleDataset_test = np.transpose(np.array(ensembleDataset_test_TRANS))
    ensembleDataset_eval = np.transpose(np.array(ensembleDataset_eval_TRANS))

    return ensembleDataset_train, ensembleDataset_test, ensembleDataset_eval

def sklearnTreeEnsembles(train_MATRIX, train_LABELS, test_MATRIX, eval_MATRIX, N, mPercent, featureSplit):

    lasttestCOLindex = len(test_MATRIX[0])-1
    test_labels = test_MATRIX[:,lasttestCOLindex]
    train_MATRIX = np.delete(train_MATRIX,-1,1)
    test_MATRIX = np.delete(test_MATRIX, -1, 1)
    eval_MATRIX = np.delete(eval_MATRIX, -1, 1)

    ensembleDataset_train_TRANS = [];    ensembleDataset_test_TRANS = [];    ensembleDataset_eval_TRANS = []
    numSamples = int(math.ceil(len(train_MATRIX) * mPercent))
    for numTrees in range(N):
        Sdata = np.array([random.choice(train_MATRIX) for _ in range(numSamples)])
        #Sdata = train_MATRIX
        predicted_train_list = [];        predicted_test_list = [];        predicted_eval_list = []
        #
        clf = tree.DecisionTreeClassifier(max_features = "sqrt")
        clf = clf.fit(train_MATRIX,train_LABELS)
        predicted_train_list = clf.predict(train_MATRIX)
        predicted_test_list = clf.predict(test_MATRIX)
        predicted_eval_list = clf.predict(eval_MATRIX)
        ensembleDataset_train_TRANS.append(predicted_train_list)
        ensembleDataset_test_TRANS.append(predicted_test_list)
        ensembleDataset_eval_TRANS.append(predicted_eval_list)

        testACCuracy = projectFunctions.accuracyMETRIC(test_labels, predicted_test_list)
        print 'After ', numTrees + 1, ' trees, Test Accuracy: ', testACCuracy

    ensembleDataset_train = np.transpose(np.array(ensembleDataset_train_TRANS))
    ensembleDataset_test = np.transpose(np.array(ensembleDataset_test_TRANS))
    ensembleDataset_eval = np.transpose(np.array(ensembleDataset_eval_TRANS))



    return ensembleDataset_train, ensembleDataset_test, ensembleDataset_eval

def allSampleTreeEnsembles(train_MATRIX, train_LABELS, test_MATRIX, eval_MATRIX, N, mPercent):
    lasttestCOLindex = len(test_MATRIX[0])-1
    test_labels = test_MATRIX[:,lasttestCOLindex]
    ensembleDataset_train_TRANS = [];    ensembleDataset_test_TRANS = [];    ensembleDataset_eval_TRANS = []
    numSamples = int(math.ceil(len(train_MATRIX) * mPercent))
    for numTrees in range(N):
        Sdata = np.array([random.choice(train_MATRIX) for _ in range(numSamples)])
        #Sdata = train_MATRIX
        predicted_train_list = []; predicted_test_list = []; predicted_eval_list = []
        num_TrainingFEATURES = len(Sdata[0])-1
        depth_of_tree = 0; limiting_depth = 10000;
        to_be_visited = range(num_TrainingFEATURES)
        major_trainLABEL = (Counter(train_LABELS)).most_common(1)[0][0]
        tree = treeFunctions.all_feautres_ID3_tree(Sdata, num_TrainingFEATURES, depth_of_tree, to_be_visited, limiting_depth)
        list_of_labels = list(Counter(train_LABELS))
        predicted_train_list = treeFunctions.predictFUNCTION(tree, train_MATRIX, list_of_labels, major_trainLABEL)
        predicted_test_list = treeFunctions.predictFUNCTION(tree, test_MATRIX, list_of_labels, major_trainLABEL)
        predicted_eval_list = treeFunctions.predictFUNCTION(tree, eval_MATRIX, list_of_labels, major_trainLABEL)
        ensembleDataset_train_TRANS.append(predicted_train_list)
        ensembleDataset_test_TRANS.append(predicted_test_list)
        ensembleDataset_eval_TRANS.append(predicted_eval_list)

        testACCuracy = projectFunctions.accuracyMETRIC( test_labels, predicted_test_list)
        print 'After ',numTrees+1,' trees, Test Accuracy: ', testACCuracy

    ensembleDataset_train = np.transpose(np.array(ensembleDataset_train_TRANS))
    ensembleDataset_test = np.transpose(np.array(ensembleDataset_test_TRANS))
    ensembleDataset_eval = np.transpose(np.array(ensembleDataset_eval_TRANS))

    return ensembleDataset_train, ensembleDataset_test, ensembleDataset_eval