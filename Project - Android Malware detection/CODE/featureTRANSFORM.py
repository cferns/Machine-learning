from __future__ import division
import projectFunctions
import numpy as np
import math
import copy
import percepFunctions
import projectFunctions
from sklearn import preprocessing
from sklearn.feature_selection import RFE
from sklearn.svm import SVR

def originalDATA(featureCASE, labelCASE):
    train_filepath = './data/data-splits/data.train'
    train_matrix, train_labels = projectFunctions.readFile_multi(train_filepath, featureCASE, labelCASE)
    eval_anon_filepath = './data/data-splits/data.eval.anon'
    eval_matrix, eval_labels = projectFunctions.readFile_multi(eval_anon_filepath, featureCASE, labelCASE)
    test_filepath = './data/data-splits/data.test'
    test_matrix, test_labels = projectFunctions.readFile_multi(test_filepath, featureCASE, labelCASE)
    return train_matrix, train_labels, test_matrix, test_labels, eval_matrix, eval_labels

def eliminateZEROfetures(featureCASE, labelCASE):
    train_filepath = './data/data-splits/data.train'
    train_matrix, train_labels = projectFunctions.readFile_multi(train_filepath, featureCASE, labelCASE)
    eval_anon_filepath = './data/data-splits/data.eval.anon'
    eval_matrix, eval_labels = projectFunctions.readFile_multi(eval_anon_filepath, featureCASE, labelCASE)
    test_filepath = './data/data-splits/data.test'
    test_matrix, test_labels = projectFunctions.readFile_multi(test_filepath, featureCASE, labelCASE)

    columnSUM = np.sum(train_matrix, axis=0)
    delLIST = []
    for i in range(len(columnSUM)):
        if columnSUM[i] <= 0:
            delLIST.append(i)
    train_matrix = np.delete(train_matrix, delLIST, axis=1)
    test_matrix = np.delete(test_matrix, delLIST, axis=1)
    eval_matrix = np.delete(eval_matrix, delLIST, axis=1)

    return train_matrix, train_labels, test_matrix, test_labels, eval_matrix, eval_labels

def onlyNORMALIZE(labelCASE, stdConstant):
    featureCASE = 'w'
    train_filepath = './data/data-splits/data.train'
    train_matrix, train_labels = projectFunctions.readFile_multi(train_filepath, featureCASE, labelCASE)
    eval_anon_filepath = './data/data-splits/data.eval.anon'
    eval_matrix, eval_labels = projectFunctions.readFile_multi(eval_anon_filepath, featureCASE, labelCASE)
    test_filepath = './data/data-splits/data.test'
    test_matrix, test_labels = projectFunctions.readFile_multi(test_filepath, featureCASE, labelCASE)
    
    #'below code is for outliers'
    numTrainRows = len(train_matrix)
    numTrainFeatures = len(train_matrix[0])
    numTestRows = len(test_matrix)
    numEvalRows = len(eval_matrix)
    for f in range(numTrainFeatures):
        stDev = np.std(train_matrix[:, f])
        meaN = np.mean(train_matrix[:, f])
        upLimit = meaN + stDev*stdConstant
        lowLimit = meaN - stDev*stdConstant
        numBuckets = math.ceil(math.sqrt(stDev))
        if numBuckets == 0:
            bucketSize = 1
        else:
            bucketSize = math.ceil(upLimit / numBuckets)
        for r in range(numTrainRows):
            if train_matrix[r][f] > upLimit:
                train_matrix[r][f] = upLimit
            #if train_matrix[r][f] < lowLimit:
            #    train_matrix[r][f] = lowLimit
            train_matrix[r][f] = math.ceil(train_matrix[r][f] / bucketSize)
            if r < numTestRows:
                if test_matrix[r][f] > upLimit:
                    test_matrix[r][f] = upLimit
                # if test_matrix[rt][f] < lowLimit:
                #    test_matrix[rt][f] = lowLimit
                test_matrix[r][f] = math.ceil(test_matrix[r][f] / bucketSize)
            if r < numEvalRows:
                if eval_matrix[r][f] > upLimit:
                    eval_matrix[r][f] = upLimit
                # if eval_matrix[rt][f] < lowLimit:
                #    eval_matrix[rt][f] = lowLimit
                eval_matrix[r][f] = math.ceil(eval_matrix[r][f] / bucketSize)
    return train_matrix, train_labels, test_matrix, test_labels, eval_matrix, eval_labels

def eliminateZEROandNORMALIZE(labelCASE, stdConstantLOW,stdConstantUP):
    featureCASE = 'w'
    train_matrix, train_labels, test_matrix, test_labels, eval_matrix, eval_labels = eliminateZEROfetures(featureCASE, labelCASE)

    # 'below code is for outliers'
    numTrainRows = len(train_matrix)
    numTrainFeatures = len(train_matrix[0])
    numTestRows = len(test_matrix)
    numEvalRows = len(eval_matrix)
    for f in range(numTrainFeatures):
        stDev = np.std(train_matrix[:, f])
        meaN = np.mean(train_matrix[:, f])
        upLimit = meaN + stDev * stdConstantUP
        lowLimit = meaN - stDev * stdConstantLOW
        numBuckets = math.ceil(math.sqrt(stDev))
        if numBuckets == 0:
            bucketSize = 1
        else:
            bucketSize = math.ceil((upLimit-lowLimit) / numBuckets)
        for r in range(numTrainRows):
            if train_matrix[r][f] > upLimit:
                train_matrix[r][f] = upLimit
            if train_matrix[r][f] < lowLimit:
                train_matrix[r][f] = lowLimit
            train_matrix[r][f] = math.ceil(train_matrix[r][f] / bucketSize)
            if r < numTestRows:
                if test_matrix[r][f] > upLimit:
                    test_matrix[r][f] = upLimit
                if test_matrix[r][f] < lowLimit:
                    test_matrix[r][f] = lowLimit
                test_matrix[r][f] = math.ceil(test_matrix[r][f] / bucketSize)
            if r < numEvalRows:
                if eval_matrix[r][f] > upLimit:
                    eval_matrix[r][f] = upLimit
                if eval_matrix[r][f] < lowLimit:
                    eval_matrix[r][f] = lowLimit
                eval_matrix[r][f] = math.ceil(eval_matrix[r][f] / bucketSize)
    return train_matrix, train_labels, test_matrix, test_labels, eval_matrix, eval_labels

def eliminateBADfeaturesWITHperceptron(finalFeatureCASE, labelCASE, thresholdBIAS):
    featureCASE = 'w'; tempList = []; delLIST = []
    train_matrix, train_labels, test_matrix, test_labels, eval_matrix, eval_labels = eliminateZEROfetures(featureCASE, labelCASE)
    for c in range(len(train_matrix[0])):
        temp_train_matrix = copy.deepcopy(train_matrix)
        temp_train_matrix = np.delete(temp_train_matrix, c, axis=1)
        w, dummy = percepFunctions.weightedPerceptron(temp_train_matrix, train_labels, 'zeros', 0.675)
        train_pred_labels = projectFunctions.prediction_Perceptron(temp_train_matrix, train_labels, w)
        acc_train = projectFunctions.accuracyMETRIC(train_labels, train_pred_labels)
        dummyP, dummyR, f1_train = projectFunctions.f1METRIC(train_labels, train_pred_labels)
        tempList.append([c,acc_train,f1_train])
        #print 'c:',c,'    acc:',acc_train,'    f1:',f1_train
    columnSUM = np.sum(tempList, axis=0)
    meanF1 = columnSUM[2]/len(tempList)
    for c in range(len(train_matrix[0])):
        if tempList[c][2] < meanF1 + thresholdBIAS:
            delLIST.append(c)
    train_matrix = np.delete(train_matrix, delLIST, axis=1)
    test_matrix = np.delete(test_matrix, delLIST, axis=1)
    eval_matrix = np.delete(eval_matrix, delLIST, axis=1)
    #
    if finalFeatureCASE == '01':
        for i in range(len(train_matrix)):
            train_matrix[i][train_matrix[i]>0]= 1
        for i in range(len(test_matrix)):
            test_matrix[i][test_matrix[i] > 0] = 1
        for i in range(len(eval_matrix)):
            eval_matrix[i][eval_matrix[i] > 0] = 1
    elif finalFeatureCASE == 'normalize':
        colRangeLIST = train_matrix.max(axis=0) - train_matrix.min(axis=0)
        for i in range(len(train_matrix)):
            for j in range(len(train_matrix[0])):
                train_matrix[i][j] = train_matrix[i][j]/colRangeLIST[j]
        colRangeLIST = test_matrix.max(axis=0) - test_matrix.min(axis=0)
        colRangeLIST[colRangeLIST == 0] = 1
        for i in range(len(test_matrix)):
            for j in range(len(test_matrix[0])):
                test_matrix[i][j] = (test_matrix[i][j])/colRangeLIST[j]
        colRangeLIST = eval_matrix.max(axis=0) - eval_matrix.min(axis=0)
        colRangeLIST[colRangeLIST == 0] = 1
        for i in range(len(eval_matrix)):
            for j in range(len(eval_matrix[0])):
                eval_matrix[i][j] = (eval_matrix[i][j])/colRangeLIST[j]
    return train_matrix, train_labels, test_matrix, test_labels, eval_matrix, eval_labels

def normalizeScale01(labelCASE):
    featureCASE = 'w'
    train_matrix, train_labels, test_matrix, test_labels, eval_matrix, eval_labels = eliminateZEROfetures(featureCASE, labelCASE)
    max_abs_scaler = preprocessing.MaxAbsScaler()
    train_matrix = max_abs_scaler.fit_transform(train_matrix)
    test_matrix = max_abs_scaler.fit_transform(test_matrix)
    eval_matrix = max_abs_scaler.fit_transform(eval_matrix)
    return train_matrix, train_labels, test_matrix, test_labels, eval_matrix, eval_labels

'''def featureELIMINATION(labelCASE):
    featureCASE = 'w'
    train_matrix, train_labels, test_matrix, test_labels, eval_matrix, eval_labels = eliminateZEROfetures(featureCASE, labelCASE)
    estimator = SVR(kernel="linear")
    selector = RFE(estimator, 50, step= 5)
    a = selector.support_
    a = int(a == 'true')

    featureCASE = 'w'
    train_matrix, train_labels, test_matrix, test_labels, eval_matrix, eval_labels = eliminateZEROfetures(featureCASE, labelCASE)
    min_max_scaler = preprocessing.MaxAbsScaler()
    train_matrix = min_max_scaler.fit_transform(train_matrix)
    test_matrix = min_max_scaler.fit_transform(test_matrix)
    eval_matrix = min_max_scaler.fit_transform(eval_matrix)
    return train_matrix, train_labels, test_matrix, test_labels, eval_matrix, eval_labels'''